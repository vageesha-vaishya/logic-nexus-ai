import fs from 'fs';
import path from 'path';
import pg from 'pg';
import dotenv from 'dotenv';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const projectRoot = path.join(__dirname, '..');

// Load environment variables
dotenv.config({ path: path.join(projectRoot, '.env') });

// Load .env.migration for DB credentials if needed
const envMigrationPath = path.join(projectRoot, '.env.migration');
let dbUrl = process.env.DATABASE_URL;

if (fs.existsSync(envMigrationPath)) {
  const content = fs.readFileSync(envMigrationPath, 'utf-8');
  content.split(/\r?\n/).forEach((line) => {
    const m = line.match(/^\s*([A-Z0-9_]+)\s*=\s*(.*)\s*$/);
    if (m) {
      const key = m[1];
      let val = m[2];
      if (val.startsWith('"') && val.endsWith('"')) val = val.slice(1, -1);
      if (key === 'SUPABASE_DB_URL' && !dbUrl) dbUrl = val;
    }
  });
}

if (!dbUrl) {
  console.error('‚ùå No DATABASE_URL or SUPABASE_DB_URL found.');
  process.exit(1);
}

const { Client } = pg;
const client = new Client({
  connectionString: dbUrl,
  ssl: { rejectUnauthorized: false }
});

// Configuration
const DOCS_DIR = join(projectRoot, 'docs');
const NON_LOGISTICS_DOC = join(DOCS_DIR, 'NON_LOGISTICS_DOMAINS.md');
const ARCHITECTURE_DOC = join(DOCS_DIR, 'SERVICE_ARCHITECTURE.md');
const DIFF_OUTPUT = join(DOCS_DIR, 'domain_sync_diff.json');

function extractDomainsFromMarkdown(filePath) {
  if (!fs.existsSync(filePath)) return [];
  const content = fs.readFileSync(filePath, 'utf-8');
  const domains = [];
  
  // Regex to match domain sections generated by sync_domains.js
  // ## Domain Name
  // ![Status](...Status-active-blue) ![Owner](...Owner-Name-green)
  // **Business Capability**: Description...
  
  const regex = /##\s+(.+)\n!\[Status\].*Status-([a-zA-Z0-9_%]+)-.*!\[Owner\].*Owner-([a-zA-Z0-9_%]+)-.*\n\n\*\*Business Capability\*\*:\s+(.+)/g;
  
  let match;
  while ((match = regex.exec(content)) !== null) {
    domains.push({
      name: match[1].trim(),
      status: decodeURIComponent(match[2]),
      owner: decodeURIComponent(match[3]),
      description: match[4].trim()
    });
  }
  return domains;
}

async function main() {
  try {
    await client.connect();
    console.log('üîå Connected to database.');

    // 1. Fetch Authoritative Data
    console.log('üì• Fetching platform_domains...');
    const dbRes = await client.query('SELECT * FROM platform_domains ORDER BY name');
    const dbDomains = dbRes.rows;

    // 2. Parse Documentation
    console.log('üìÑ Parsing documentation...');
    const nonLogisticsDomains = extractDomainsFromMarkdown(NON_LOGISTICS_DOC);
    const architectureDomains = extractDomainsFromMarkdown(ARCHITECTURE_DOC);
    
    // Combine doc domains, keyed by name for easy lookup
    const docDomainsMap = new Map();
    [...nonLogisticsDomains, ...architectureDomains].forEach(d => {
      docDomainsMap.set(d.name, d);
    });

    // 3. Compare & Diff
    const diff = {
      missing_in_docs: [],
      missing_in_db: [], // Orphans
      attribute_mismatches: []
    };

    // Check DB domains against Docs
    for (const dbDom of dbDomains) {
      const docDom = docDomainsMap.get(dbDom.name);
      
      if (!docDom) {
        diff.missing_in_docs.push(dbDom.key);
      } else {
        // Compare attributes
        const mismatches = [];
        
        // Normalize status
        const dbStatus = (dbDom.status || 'planned').toLowerCase();
        const docStatus = (docDom.status || '').toLowerCase();
        if (dbStatus !== docStatus) {
            mismatches.push({ field: 'status', db: dbStatus, doc: docStatus });
        }

        // Normalize owner (handle nulls)
        const dbOwner = (dbDom.owner || 'Unassigned').trim();
        const docOwner = (docDom.owner || 'Unassigned').trim();
        if (dbOwner !== docOwner) {
             mismatches.push({ field: 'owner', db: dbOwner, doc: docOwner });
        }
        
        // Description check (loose comparison to avoid whitespace issues)
        const dbDesc = (dbDom.description || '').trim();
        const docDesc = (docDom.description || '').trim();
        // Just check if doc starts with DB desc or matches closely, as docs might have extra markdown
        if (!docDesc.includes(dbDesc)) {
             mismatches.push({ field: 'description', db: dbDesc, doc: docDesc });
        }

        if (mismatches.length > 0) {
          diff.attribute_mismatches.push({
            domain: dbDom.key,
            mismatches
          });
        }
        
        // Mark as visited
        docDomainsMap.delete(dbDom.name);
      }
    }

    // Remaining doc domains are orphans (missing in DB)
    for (const [name, docDom] of docDomainsMap) {
      diff.missing_in_db.push(name);
    }

    // 4. Output Results
    fs.writeFileSync(DIFF_OUTPUT, JSON.stringify(diff, null, 2));
    console.log(`üíæ Diff artifact saved to ${DIFF_OUTPUT}`);

    const varianceCount = diff.missing_in_docs.length + diff.missing_in_db.length + diff.attribute_mismatches.length;

    if (varianceCount > 0) {
      console.error('‚ùå Validation Failed: Variance detected between Database and Documentation.');
      console.error(JSON.stringify(diff, null, 2));
      process.exit(1);
    } else {
      console.log('‚úÖ Validation Passed: Zero variance detected.');
      process.exit(0);
    }

  } catch (err) {
    console.error('‚ùå Error:', err);
    process.exit(1);
  } finally {
    await client.end();
  }
}

main();
